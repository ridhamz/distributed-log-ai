# Distributed Log Processing with AI Agent

## ğŸ“– Overview

This project is a **Distributed Log Processing System** built with **Node.js (TypeScript)**, **AWS**, and **AI Agent (Claude)**.  
It is designed to handle large volumes of log data in **real time**, detect anomalies using AI, and store insights in a **scalable distributed architecture**.

### ğŸ¯ Key Features

- **Log Ingestion Service** â†’ Accepts logs from distributed clients.
- **Queue Processing** â†’ Uses **AWS SQS** for scalable log streaming.
- **AI Anomaly Detection** â†’ Sends logs to **Claude API** for anomaly detection.
- **Storage & Metadata** â†’ Stores processed log metadata in **DynamoDB**.
- **Distributed Workers** â†’ Multiple worker nodes can consume logs concurrently.
- **Alerts** â†’ Sends **SNS email alerts** for critical logs.
- **Dashboard-ready** â†’ Exposes APIs for monitoring & future integration with Grafana/React dashboards.

---

## ğŸ— Architecture

![AWS Architecture](./docs/arch.png)

---

## âš™ï¸ Tech Stack

- **Backend Runtime** â†’ Node.js + TypeScript
- **Queue** â†’ AWS SQS
- **Storage** â†’ DynamoDB (metadata & analyzed logs)
- **AI Integration** â†’ Claude (Anthropic API) for anomaly detection
- **Alerts** â†’ AWS SNS for critical logs
- **Config & Secrets** â†’ dotenv + `.env`
- **Monitoring Ready** â†’ Exposes REST APIs for dashboards

---

## ğŸš€ Setup & Run

### 1ï¸âƒ£ Clone Repo

```bash
git clone https://github.com/ridhamz/distributed-log-ai.git
cd distributed-log-ai
```

### 2ï¸âƒ£ Install Dependencies

```bash
npm install
```

### 3ï¸âƒ£ Configure Environment

Create a `.env` file in root:

```env
AWS_REGION=us-east-1
SQS_QUEUE_URL=https://sqs.us-east-1.amazonaws.com/123456789012/log-queue
DYNAMO_TABLE=ProcessedLogs
SNS_TOPIC_ARN=arn:aws:sns:us-east-1:123456789012:CriticalLogAlerts
CLAUDE_API_KEY=your-claude-api-key
CLAUDE_MODEL=claude-3-opus-20240229
PORT=4000
```

### 4ï¸âƒ£ Run in Dev Mode

```bash
npm run dev
```

### 5ï¸âƒ£ Run in Prod Mode (compiled)

```bash
npm run build
npm start
```

---

## ğŸ”Œ AWS + AI Integration

- **Logs ingestion** â†’ API receives logs and pushes them to **SQS queue**.
- **Workers** â†’ Consume messages from SQS and insert metadata / processed logs into **DynamoDB**.
- **AI (Claude)** â†’ Selected logs are passed to **Claude** for anomaly detection.
- **Alerts** â†’ Critical logs trigger **SNS email notifications**.
- **Insights** â†’ Results are stored in DynamoDB and exposed via REST APIs.

---

## ğŸ“Š Future Improvements

- Add **Grafana dashboard** for real-time visualization.
- Support **multi-region replication** for HA.
- Introduce **stream-based training** for AI models (self-learning).
